# SQLC Python Code Generation Tool Design

## Overview

Build a custom SQLc code generation plugin (`tools/sqlc_gen_python/__main__.py`) that reads protobuf input from stdin and generates Python code for database models and query functions.

## End State

The tool will replace the current SQLc Go-based code generation with a Python-native solution that:

1. **Generates model dataclasses** from database table schemas
2. **Generates standalone query functions** (not class methods) that accept `DBConn` and parameters
3. **Maintains compatibility** with existing generated code patterns

## Input/Output Flow

```
[SQLc] -> [stdin: protobuf GenerateRequest] -> [sqlc_gen_python] -> [stdout: protobuf GenerateResponse] -> [SQLc]
```

## Generated Code Structure

### Models (database/__codegen__/models.py)
```python
# Code generated by sqlc. DO NOT EDIT.
import dataclasses
import datetime
from typing import Any

@dataclasses.dataclass(slots=True)
class Organization:
    id: str
    created_at: datetime.datetime
    updated_at: datetime.datetime
    storytime: Any | None
    name: str
    inbound_source: str
```

### Queries (database/__codegen__/queries.py)
```python
# Code generated by sqlc. DO NOT EDIT.
import datetime
from typing import AsyncIterator
from database.conn import DBConn
from database.__codegen__ import models

ORGANIZATION_FETCH = """-- name: organization_fetch \\:one
SELECT id, created_at, updated_at, storytime, name, inbound_source
FROM organizations
WHERE id = :p1
"""

async def organization_fetch(conn: DBConn, *, id: str) -> models.Organization | None:
    row = (await conn.execute(sqlalchemy.text(ORGANIZATION_FETCH), {"p1": id})).first()
    if row is None:
        return None
    return models.Organization(
        id=row[0],
        created_at=row[1],
        updated_at=row[2],
        storytime=row[3],
        name=row[4],
        inbound_source=row[5],
    )
```

## Key Components

### 1. Protobuf Handling
- Deserialize `GenerateRequest` from stdin
- Serialize `GenerateResponse` to stdout
- Handle binary protobuf encoding/decoding

### 2. Type Mapping System
```python
POSTGRES_TO_PYTHON_TYPES = {
    "text": "str",
    "varchar": "str", 
    "timestamptz": "datetime.datetime",
    "boolean": "bool",
    "jsonb": "Any | None",
    "bigint": "int",
    # ... more mappings
}
```

### 3. Model Generation
- Parse `Catalog.schemas[].tables[]` from protobuf
- Generate `@dataclasses.dataclass(slots=True)` classes
- Handle nullable columns with `T | None`
- Generate proper imports

### 4. Query Function Generation
- Parse `queries[]` from protobuf
- Generate standalone async functions (not class methods)
- Handle query types: `:one`, `:many`, `:exec`
- Generate parameter mapping from `:pN` placeholders
- Generate proper return types based on query command

## Implementation Architecture

```
__main__.py
├── POSTGRES_TO_PYTHON_TYPES - Type mapping constant
├── main() - CLI entry point
├── deserialize_request() - Parse stdin protobuf
├── generate_models() - Create dataclass models
├── generate_queries() - Create query functions  
└── serialize_response() - Write stdout protobuf
```

## Integration Points

- Uses existing `database.conn.DBConn` type
- Generates code compatible with current `database/__codegen__/` structure
- Integrates with `just codegen-db` workflow
- Maintains import patterns from existing generated code

## Testing Strategy

- Unit tests in `__main__test.py` using Click testing utilities
- Test protobuf serialization/deserialization 
- Test model generation from sample schema
- Test query generation from sample queries
- End-to-end test with actual database schema