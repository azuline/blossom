# SQLC Python Code Generation Tool Design

## Overview

Build a custom SQLc code generation plugin (`tools/sqlc_gen_python/__main__.py`) that reads protobuf input from stdin and generates Python code for database models and query functions.

## End State

The tool will replace the current SQLc Go-based code generation with a Python-native solution that:

1. **Generates model dataclasses** from database table schemas
2. **Generates standalone query functions** (not class methods) that accept `DBConn` and parameters
3. **Maintains compatibility** with existing generated code patterns

## Input/Output Flow

```
[SQLc] -> [stdin: protobuf GenerateRequest] -> [sqlc_gen_python] -> [stdout: protobuf GenerateResponse] -> [SQLc]
```

## Generated Code Structure

### Models (database/__codegen__/models.py)
```python
# Code generated by sqlc. DO NOT EDIT.
import dataclasses
import datetime
from typing import Any

@dataclasses.dataclass(slots=True)
class Organization:
    id: str
    created_at: datetime.datetime
    updated_at: datetime.datetime
    storytime: dict[str, Any] | None  # JSON/JSONB typed as dict[str, Any]
    name: str
    inbound_source: str
```

### Queries (database/__codegen__/queries.py)
```python
# Code generated by sqlc. DO NOT EDIT.
import datetime
from typing import AsyncIterator
from database.conn import DBConn
from database.__codegen__ import models

ORGANIZATION_FETCH = """-- name: organization_fetch \\:one
SELECT id, created_at, updated_at, storytime, name, inbound_source
FROM organizations
WHERE id = :p1
"""

async def organization_fetch(conn: DBConn, *, id: str) -> models.Organization:
    row = (await conn.execute(sqlalchemy.text(ORGANIZATION_FETCH), {"p1": id})).first()
    if row is None:
        raise NotFoundError("organization not found", id=id)
    return models.Organization(
        id=row[0],
        created_at=row[1],
        updated_at=row[2],
        storytime=row[3],
        name=row[4],
        inbound_source=row[5],
    )
```

### Enums (database/__codegen__/enums.py)
```python
# Code generated by sqlc. DO NOT EDIT.
from typing import Literal

# Generated from user_status_enum table
type UserStatusEnum = Literal["active", "inactive", "suspended"]
USER_STATUS_ENUM_VALUES = ["active", "inactive", "suspended"]

# Generated from priority_level_enum table  
type PriorityLevelEnum = Literal["low", "medium", "high", "critical"]
PRIORITY_LEVEL_ENUM_VALUES = ["low", "medium", "high", "critical"]
```

## Key Components

### 1. Protobuf Handling
- Deserialize `GenerateRequest` from stdin
- Serialize `GenerateResponse` to stdout
- Handle binary protobuf encoding/decoding

### 2. Type Mapping System
```python
POSTGRES_TO_PYTHON_TYPES = {
    "text": "str",
    "varchar": "str", 
    "timestamptz": "datetime.datetime",
    "boolean": "bool",
    "jsonb": "dict[str, Any]",  # Updated for better type safety
    "json": "dict[str, Any]",   # Updated for better type safety
    "bigint": "int",
    # ... more mappings
}
```

### 3. Model Generation
- Parse `Catalog.schemas[].tables[]` from protobuf
- Filter to only "public" schema tables
- Skip tables ending with `_enum` (handled separately)
- De-pluralize table names for class names (users → User)
- Generate `@dataclasses.dataclass(slots=True)` classes
- Handle nullable columns with `T | None`
- Generate proper imports

### 4. Enum Generation  
- Detect tables with `_enum` suffix
- Connect to testdb database to query enum values
- Generate `enums.py` with `Literal` type aliases and value lists
- Format: `type XEnum = Literal[...]` and `X_ENUM_VALUES = [...]`
- Exclude enum tables from regular model generation

### 5. Query Function Generation
- Parse `queries[]` from protobuf
- Generate standalone async functions (not class methods)
- Handle query types: `:one`, `:many`, `:exec`
- For `:one` queries: raise `NotFoundError` instead of returning `None`
- Generate parameter mapping from `:pN` placeholders
- Generate proper return types (no `| None` for `:one` queries)

## Implementation Architecture

```
__main__.py
├── POSTGRES_TO_PYTHON_TYPES - Type mapping constant
├── main() - CLI entry point
├── deserialize_request() - Parse stdin protobuf
├── generate_models() - Create dataclass models
├── generate_enums() - Create enum types from _enum tables
├── generate_queries() - Create query functions  
├── _connect_to_testdb() - Database connection for enum queries
├── _depluralize_table_name() - Convert plural to singular names
└── serialize_response() - Write stdout protobuf
```

## Integration Points

- Uses existing `database.conn.DBConn` type
- Uses `foundation.observability.errors.NotFoundError` for error handling
- Generates code compatible with current `database/__codegen__/` structure
- Integrates with `just codegen-db` workflow
- Maintains import patterns from existing generated code
- Connects to testdb database for enum value queries

## Testing Strategy

- Unit tests in `__main__test.py` using Click testing utilities
- Test protobuf serialization/deserialization 
- Test model generation from sample schema
- Test enum generation with mock database queries
- Test query generation with NotFoundError handling
- Test JSON/JSONB type mapping updates
- End-to-end test with actual database schema

## New Features Summary

### 1. Enhanced Error Handling
- `:one` queries now raise `NotFoundError` instead of returning `None`
- Return types for `:one` queries no longer include `| None`
- Provides better error context with relevant parameters

### 2. Enum Type Generation  
- Tables ending with `_enum` generate `Literal` types instead of dataclasses
- Creates separate `enums.py` file with type aliases and value lists
- Dynamically queries testdb database for actual enum values
- Format: `type StatusEnum = Literal["active", "inactive"]`

### 3. Improved Type Safety
- JSON/JSONB fields typed as `dict[str, Any]` instead of `Any`
- Better IntelliSense and type checking for JSON data
- Maintains nullability with `dict[str, Any] | None` for nullable columns