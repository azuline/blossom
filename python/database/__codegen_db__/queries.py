# Code generated by sqlc. DO NOT EDIT.
import dataclasses
import datetime
from typing import Any, AsyncIterator
import sqlalchemy
import psycopg
from database.conn import DBConn
from database.__codegen_db__ import models
from foundation.observability.errors import NotFoundError

@dataclasses.dataclass(slots=True)
class TestBulkInsertsData:
    name: str
    inbound_source: str

@dataclasses.dataclass(slots=True)
class TestBatchUpsertOrganizationsData:
    id: str
    name: str
    inbound_source: str

@dataclasses.dataclass(slots=True)
class TestBatchCreateUsersData:
    name: str
    email: str

@dataclasses.dataclass(slots=True)
class UserModel:
    id: str
    name: str
    email: str

@dataclasses.dataclass(slots=True)
class TestBatchUpdateUserVisitedData:
    name: str

@dataclasses.dataclass(slots=True)
class TestBatchUpdateUserVisitedResult:
    id: str
    name: str
    last_visited_at: datetime.datetime | None

TEST_BULK_INSERTS = r"""-- name: test_bulk_inserts \:copyfrom
INSERT INTO organizations (name, inbound_source) VALUES (:p1, :p2)
"""

async def query_test_bulk_inserts(conn: DBConn, data: list[TestBulkInsertsData]) -> None:
    # Use psycopg connection for bulk insert via COPY FROM
    raw_conn = await conn.get_raw_connection()
    assert raw_conn.driver_connection
    async with raw_conn.driver_connection.cursor() as cursor:
        # Convert INSERT statement to COPY FROM format
        copy_sql = f"COPY organizations (name, inbound_source) FROM STDIN"
        async with cursor.copy(copy_sql) as copy:
            for item in data:
                await copy.write_row((item.name, item.inbound_source))

TEST_BATCH_UPSERT_ORGANIZATIONS = r"""-- name: test_batch_upsert_organizations \:batchexec
INSERT INTO organizations (id, name, inbound_source) VALUES (:p1, :p2, :p3) 
ON CONFLICT (id) DO UPDATE SET inbound_source = EXCLUDED.inbound_source
"""

async def query_test_batch_upsert_organizations(conn: DBConn, batch_data: list[TestBatchUpsertOrganizationsData]) -> None:
    await conn.execute(sqlalchemy.text(TEST_BATCH_UPSERT_ORGANIZATIONS), [{"p1": batch_item.id, "p2": batch_item.name, "p3": batch_item.inbound_source} for batch_item in batch_data])

TEST_BATCH_CREATE_USERS = r"""-- name: test_batch_create_users \:batchone
INSERT INTO users (name, email) VALUES (:p1, :p2) RETURNING id, name, email
"""

async def query_test_batch_create_users(conn: DBConn, batch_data: list[TestBatchCreateUsersData]) -> AsyncIterator[UserModel]:
    # Use psycopg connection for batch execution with RETURNING
    raw_conn = await conn.get_raw_connection()
    assert raw_conn.driver_connection
    async with raw_conn.driver_connection.cursor() as cursor:
        psycopg_sql = 'INSERT INTO users (name, email) VALUES (%(p1)s, %(p2)s) RETURNING id, name, email'
        await cursor.executemany(psycopg_sql, [{"p1": batch_item.name, "p2": batch_item.email} for batch_item in batch_data], returning=True)
        # For executemany with returning=True, we need to iterate through all result sets
        assert cursor.pgresult
        while True:
            async for row in cursor:
                yield UserModel(
                    id=row[0],
                    name=row[1],
                    email=row[2],
                )
            if not cursor.nextset():
                break

TEST_BATCH_UPDATE_USER_VISITED = r"""-- name: test_batch_update_user_visited \:batchmany
UPDATE users SET last_visited_at = NOW() WHERE name = :p1 RETURNING id, name, last_visited_at
"""

async def query_test_batch_update_user_visited(conn: DBConn, batch_data: list[TestBatchUpdateUserVisitedData]) -> AsyncIterator[TestBatchUpdateUserVisitedResult]:
    # Use psycopg connection for batch execution with RETURNING
    raw_conn = await conn.get_raw_connection()
    assert raw_conn.driver_connection
    async with raw_conn.driver_connection.cursor() as cursor:
        psycopg_sql = 'UPDATE users SET last_visited_at = NOW() WHERE name = %(p1)s RETURNING id, name, last_visited_at'
        await cursor.executemany(psycopg_sql, [{"p1": batch_item.name} for batch_item in batch_data], returning=True)
        # For executemany with returning=True, we need to iterate through all result sets
        assert cursor.pgresult
        while True:
            async for row in cursor:
                yield TestBatchUpdateUserVisitedResult(
                    id=row[0],
                    name=row[1],
                    last_visited_at=row[2],
                )
            if not cursor.nextset():
                break

