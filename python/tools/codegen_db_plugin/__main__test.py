"""Tests for codegen_db_plugin tool."""

import sqlalchemy
from click.testing import CliRunner

from database.conn import connect_db_admin
from tools.codegen_db_plugin.__main__ import generate_enums, generate_models, generate_queries, main
from tools.codegen_db_plugin.proto import Catalog, Column, GenerateRequest, GenerateResponse, Identifier, Parameter, Query, Schema, Settings, Table


def test_protobuf_serialization_roundtrip():
    """Test that we can serialize and deserialize protobuf messages correctly."""
    # Create a sample GenerateRequest
    request = GenerateRequest(
        sqlc_version="1.0.0",
        settings=Settings(version="1.0.0", engine="postgresql"),
        catalog=Catalog(
            name="test_db",
            default_schema="public",
            schemas=[
                Schema(
                    name="public",
                    tables=[
                        Table(
                            rel=Identifier(name="users", schema="public"),
                            columns=[Column(name="id", not_null=True, type=Identifier(name="bigint")), Column(name="name", not_null=True, type=Identifier(name="text"))],
                        )
                    ],
                )
            ],
        ),
        queries=[Query(name="get_user", text="SELECT id, name FROM users WHERE id = $1", cmd=":one")],
    )

    # Test serialization
    serialized = bytes(request)
    assert len(serialized) > 0

    # Test deserialization
    deserialized = GenerateRequest().parse(serialized)

    # Verify the data was preserved
    assert deserialized.sqlc_version == "1.0.0"
    assert deserialized.settings.version == "1.0.0"
    assert deserialized.catalog.name == "test_db"
    assert len(deserialized.catalog.schemas) == 1
    assert deserialized.catalog.schemas[0].name == "public"
    assert len(deserialized.catalog.schemas[0].tables) == 1
    assert deserialized.catalog.schemas[0].tables[0].rel.name == "users"
    assert len(deserialized.catalog.schemas[0].tables[0].columns) == 2
    assert len(deserialized.queries) == 1
    assert deserialized.queries[0].name == "get_user"


def test_cli_basic_functionality():
    """Test that the CLI tool can handle basic protobuf input/output."""
    runner = CliRunner()

    # Create a minimal GenerateRequest with empty catalog and queries
    request = GenerateRequest(sqlc_version="1.0.0", settings=Settings(version="1.0.0", engine="postgresql"), catalog=Catalog(name="test", schemas=[]))

    # Serialize request
    input_data = bytes(request)

    # Run the CLI tool with the expected service method
    result = runner.invoke(main, ["/plugin.CodegenService/Generate"], input=input_data)

    # Check that it ran without errors
    assert result.exit_code == 0

    # Parse the output as a GenerateResponse
    response = GenerateResponse().parse(result.stdout_bytes)

    # Verify response structure and exact content
    file_names = {f.name for f in response.files}
    expected_files = {"database/__codegen_db__/__init__.py", "database/__codegen_db__/models.py", "database/__codegen_db__/enums.py"}
    assert file_names == expected_files

    # Check exact content by finding files by name
    files_by_name = {f.name: f for f in response.files}

    # Check exact __init__.py content (should be empty)
    assert files_by_name["database/__codegen_db__/__init__.py"].contents == b""

    # Check exact models.py content (empty catalog should produce minimal output)
    expected_models = """\
# Code generated by sqlc. DO NOT EDIT.
import dataclasses
import datetime
from typing import Any

"""
    assert files_by_name["database/__codegen_db__/models.py"].contents.decode("utf-8") == expected_models

    # Check exact enums.py content (empty catalog should produce minimal output)
    expected_enums = """\
# Code generated by sqlc. DO NOT EDIT.
from typing import Literal

"""
    assert files_by_name["database/__codegen_db__/enums.py"].contents.decode("utf-8") == expected_enums


def test_cli_with_service_method():
    """Test that the CLI tool handles the gRPC service method argument correctly."""
    runner = CliRunner()

    request = GenerateRequest(sqlc_version="1.0.0", settings=Settings(version="1.0.0", engine="postgresql"), catalog=Catalog(name="test", schemas=[]))
    input_data = bytes(request)
    result = runner.invoke(main, ["/plugin.CodegenService/Generate"], input=input_data)
    assert result.exit_code == 0

    response = GenerateResponse().parse(result.stdout_bytes)
    file_names = {f.name for f in response.files}
    expected_files = {"database/__codegen_db__/__init__.py", "database/__codegen_db__/models.py", "database/__codegen_db__/enums.py"}
    assert file_names == expected_files


async def test_model_generation():
    """Test database model dataclass generation."""
    # Create a sample catalog with a table
    catalog = Catalog(
        name="test_db",
        schemas=[
            Schema(
                name="public",
                tables=[
                    Table(
                        rel=Identifier(name="users", schema="public"),
                        columns=[
                            Column(name="id", not_null=True, type=Identifier(name="bigint")),
                            Column(name="name", not_null=True, type=Identifier(name="text")),
                            Column(name="email", not_null=False, type=Identifier(name="text")),
                            Column(name="created_at", not_null=True, type=Identifier(name="timestamptz")),
                            Column(name="tags", not_null=False, is_array=True, type=Identifier(name="text")),
                            Column(name="metadata", not_null=False, type=Identifier(name="jsonb")),
                        ],
                    )
                ],
            )
        ],
    )

    # Generate models
    models_code = await generate_models(catalog)

    # Assert exact expected output (de-pluralized: users -> User)
    expected_code = """\
# Code generated by sqlc. DO NOT EDIT.
import dataclasses
import datetime
from typing import Any

@dataclasses.dataclass(slots=True)
class UserModel:
    id: int
    name: str
    email: str | None
    created_at: datetime.datetime
    tags: list[str] | None
    metadata: dict[str, Any] | None

"""
    assert models_code == expected_code


def test_query_generation():
    """Test query function generation."""
    # Create sample queries
    queries = [
        Query(
            name="get_user",
            text="SELECT id, name, email FROM users WHERE id = $1",
            cmd=":one",
            params=[Parameter(number=1, column=Column(name="id", not_null=True, type=Identifier(name="bigint")))],
            columns=[
                Column(name="id", not_null=True, type=Identifier(name="bigint"), table=Identifier(name="users")),
                Column(name="name", not_null=True, type=Identifier(name="text"), table=Identifier(name="users")),
                Column(name="email", not_null=False, type=Identifier(name="text"), table=Identifier(name="users")),
            ],
        ),
        Query(
            name="list_users",
            text="SELECT id, name, email FROM users",
            cmd=":many",
            columns=[
                Column(name="id", not_null=True, type=Identifier(name="bigint"), table=Identifier(name="users")),
                Column(name="name", not_null=True, type=Identifier(name="text"), table=Identifier(name="users")),
                Column(name="email", not_null=False, type=Identifier(name="text"), table=Identifier(name="users")),
            ],
        ),
        Query(
            name="delete_user",
            text="DELETE FROM users WHERE id = $1",
            cmd=":exec",
            params=[Parameter(number=1, column=Column(name="id", not_null=True, type=Identifier(name="bigint")))],
        ),
    ]

    # Generate queries - without catalog, should use fallback naming
    queries_code = generate_queries(queries)

    # Assert exact expected output
    expected_code = '''\
# Code generated by sqlc. DO NOT EDIT.
import dataclasses
import datetime
from typing import Any, AsyncIterator
import sqlalchemy
import psycopg
from database.conn import DBConn
from database.__codegen_db__ import models
from foundation.observability.errors import NotFoundError

GET_USER = """\\
SELECT id, name, email FROM users WHERE id = :p1
"""

async def query_get_user(conn: DBConn, *, id: int) -> models.GetUserResult:
    row = (await conn.execute(sqlalchemy.text(GET_USER), {"p1": id})).first()
    if row is None:
        raise NotFoundError(resource="get_user", key_name="id", key_value=str(id))
    return models.GetUserResult(
        id=row[0],
        name=row[1],
        email=row[2],
    )

LIST_USERS = """\\
SELECT id, name, email FROM users
"""

async def query_list_users(conn: DBConn) -> AsyncIterator[models.ListUsersResult]:
    result = await conn.execute(sqlalchemy.text(LIST_USERS), {})
    for row in result:
        yield models.ListUsersResult(
            id=row[0],
            name=row[1],
            email=row[2],
        )

DELETE_USER = """\\
DELETE FROM users WHERE id = :p1
"""

async def query_delete_user(conn: DBConn, *, id: int) -> None:
    await conn.execute(sqlalchemy.text(DELETE_USER), {"p1": id})

'''
    assert queries_code == expected_code


def test_copyfrom_query_generation():
    """Test that :copyfrom queries generate proper bulk insert functionality."""
    # Create test queries with :copyfrom annotation on INSERT statement
    queries = [
        Query(
            name="bulk_insert_users",
            text="INSERT INTO users (name, email) VALUES ($1, $2)",
            cmd=":copyfrom",
            params=[
                Parameter(number=1, column=Column(name="name", not_null=True, type=Identifier(name="text"))),
                Parameter(number=2, column=Column(name="email", not_null=False, type=Identifier(name="text"))),
            ],
            insert_into_table=Identifier(name="users"),
        ),
    ]

    # Generate queries
    queries_code = generate_queries(queries)

    # Assert exact expected output with dataclass and bulk insert
    expected_code = '''\
# Code generated by sqlc. DO NOT EDIT.
import dataclasses
import datetime
from typing import Any, AsyncIterator
import sqlalchemy
import psycopg
from database.conn import DBConn
from database.__codegen_db__ import models
from foundation.observability.errors import NotFoundError

@dataclasses.dataclass(slots=True)
class BulkInsertUsersData:
    name: str
    email: str | None

BULK_INSERT_USERS = """\\
COPY users (name, email) FROM STDIN
"""

async def query_bulk_insert_users(conn: DBConn, data: list[BulkInsertUsersData]) -> None:
    raw_conn = await conn.get_raw_connection()
    assert raw_conn.driver_connection
    async with raw_conn.driver_connection.cursor() as cursor:
        async with cursor.copy(BULK_INSERT_USERS) as copy:
            for item in data:
                await copy.write_row((item.name, item.email))

'''
    assert queries_code == expected_code


async def test_schema_filtering_and_depluralization():
    """Test that only public schema tables are included and names are de-pluralized."""
    # Create a catalog with both public and non-public schemas, plus yoyo tables
    catalog = Catalog(
        name="test_db",
        schemas=[
            Schema(
                name="public",
                tables=[
                    Table(
                        rel=Identifier(name="users", schema="public"),
                        columns=[Column(name="id", not_null=True, type=Identifier(name="bigint"))],
                    ),
                    Table(
                        rel=Identifier(name="companies", schema="public"),
                        columns=[Column(name="id", not_null=True, type=Identifier(name="bigint"))],
                    ),
                    Table(
                        rel=Identifier(name="_yoyo_migrations", schema="public"),
                        columns=[Column(name="id", not_null=True, type=Identifier(name="bigint"))],
                    ),
                ],
            ),
            Schema(
                name="internal",
                tables=[
                    Table(
                        rel=Identifier(name="logs", schema="internal"),
                        columns=[Column(name="id", not_null=True, type=Identifier(name="bigint"))],
                    )
                ],
            ),
        ],
    )

    # Generate models
    models_code = await generate_models(catalog)

    # Assert that only public schema tables are included, names are de-pluralized, and yoyo tables are filtered out
    expected_code = """\
# Code generated by sqlc. DO NOT EDIT.
import dataclasses
import datetime
from typing import Any

@dataclasses.dataclass(slots=True)
class UserModel:
    id: int

@dataclasses.dataclass(slots=True)
class CompanyModel:
    id: int

"""
    assert models_code == expected_code


async def test_enum_filtering():
    """Test that _enum tables are excluded from regular model generation."""
    # Create a catalog with both regular and enum tables
    catalog = Catalog(
        name="test_db",
        schemas=[
            Schema(
                name="public",
                tables=[
                    Table(
                        rel=Identifier(name="users", schema="public"),
                        columns=[Column(name="id", not_null=True, type=Identifier(name="bigint"))],
                    ),
                    Table(
                        rel=Identifier(name="status_enum", schema="public"),
                        columns=[Column(name="value", not_null=True, type=Identifier(name="text"))],
                    ),
                ],
            ),
        ],
    )

    # Generate models - should only include non-enum tables
    models_code = await generate_models(catalog)

    # Assert that only the users table is included (not status_enum)
    # But since there's an enum table present, it should include the enum import
    expected_models = """\
# Code generated by sqlc. DO NOT EDIT.
import dataclasses
import datetime
from typing import Any

from database.__codegen_db__ import enums
@dataclasses.dataclass(slots=True)
class UserModel:
    id: int

"""
    assert models_code == expected_models

    # Also test enum generation by creating a test enum table
    # Create a test enum table and populate it
    async with connect_db_admin() as conn:
        # Create the test enum table
        await conn.execute(sqlalchemy.text("CREATE TABLE IF NOT EXISTS status_enum (value TEXT PRIMARY KEY)"))

        # Insert test values
        await conn.execute(sqlalchemy.text("DELETE FROM status_enum"))  # Clean any existing data
        await conn.execute(sqlalchemy.text("INSERT INTO status_enum (value) VALUES ('active'), ('inactive'), ('pending')"))

        # Test with a catalog that references this enum table
        enum_catalog = Catalog(
            name="test_db",
            schemas=[
                Schema(
                    name="public",
                    tables=[
                        Table(
                            rel=Identifier(name="status_enum", schema="public"),
                            columns=[Column(name="value", not_null=True, type=Identifier(name="text"))],
                        ),
                    ],
                ),
            ],
        )

        # Generate enums - should now find our test data
        enums_code = await generate_enums(enum_catalog)

        # Clean up the test table
        await conn.execute(sqlalchemy.text("DROP TABLE IF EXISTS status_enum"))

    # Verify the generated enum code
    expected_enums = """# Code generated by sqlc. DO NOT EDIT.
from typing import Literal

type StatusEnum = Literal["active", "inactive", "pending"]
STATUS_ENUM_VALUES = ['active', 'inactive', 'pending']

"""
    assert enums_code == expected_enums


async def test_enum_foreign_key_mapping():
    """Test that columns with foreign keys to enum tables use enum types."""
    # Create actual database tables with foreign key relationship
    async with connect_db_admin() as conn:
        # Create the test enum table and regular table with FK
        await conn.execute(sqlalchemy.text("CREATE TABLE IF NOT EXISTS status_enum (value TEXT PRIMARY KEY)"))
        await conn.execute(sqlalchemy.text("CREATE TABLE IF NOT EXISTS test_users (id BIGINT PRIMARY KEY, name TEXT NOT NULL, status TEXT REFERENCES status_enum(value))"))

        # Insert test values
        await conn.execute(sqlalchemy.text("DELETE FROM status_enum"))
        await conn.execute(sqlalchemy.text("INSERT INTO status_enum (value) VALUES ('active'), ('inactive'), ('pending')"))

        try:
            # Create a catalog with the tables that have FK relationships
            catalog = Catalog(
                name="test_db",
                schemas=[
                    Schema(
                        name="public",
                        tables=[
                            Table(
                                rel=Identifier(name="status_enum", schema="public"),
                                columns=[Column(name="value", not_null=True, type=Identifier(name="text"))],
                            ),
                            Table(
                                rel=Identifier(name="test_users", schema="public"),
                                columns=[
                                    Column(name="id", not_null=True, type=Identifier(name="bigint"), table=Identifier(name="test_users")),
                                    Column(name="name", not_null=True, type=Identifier(name="text"), table=Identifier(name="test_users")),
                                    Column(name="status", not_null=True, type=Identifier(name="text"), table=Identifier(name="test_users")),  # FK to status_enum
                                ],
                            ),
                        ],
                    ),
                ],
            )

            # Generate models
            models_code = await generate_models(catalog)

            # Should include enum import and use StatusEnum type
            expected_models = """# Code generated by sqlc. DO NOT EDIT.
import dataclasses
import datetime
from typing import Any

from database.__codegen_db__ import enums
@dataclasses.dataclass(slots=True)
class TestUserModel:
    id: int
    name: str
    status: enums.StatusEnum

"""
            assert models_code == expected_models

        finally:
            # Clean up the test tables
            await conn.execute(sqlalchemy.text("DROP TABLE IF EXISTS test_users"))
            await conn.execute(sqlalchemy.text("DROP TABLE IF EXISTS status_enum"))


def test_query_grouping_by_filename():
    """Test that queries are grouped by filename and generate separate query files."""
    runner = CliRunner()

    # Create queries with different filepaths
    queries = [
        Query(name="get_user", text="SELECT * FROM users WHERE id = $1", cmd=":one", filepath="database/queries.sql"),
        Query(name="list_users", text="SELECT * FROM users", cmd=":many", filepath="database/queries.sql"),
        Query(name="get_product", text="SELECT * FROM products WHERE id = $1", cmd=":one", filepath="product/queries.sql"),
        Query(name="list_products", text="SELECT * FROM products", cmd=":many", filepath="product/queries.sql"),
    ]

    request = GenerateRequest(sqlc_version="1.0.0", settings=Settings(version="1.0.0", engine="postgresql"), catalog=Catalog(name="test", schemas=[]), queries=queries)

    input_data = bytes(request)
    result = runner.invoke(main, ["/plugin.CodegenService/Generate"], input=input_data)
    assert result.exit_code == 0

    response = GenerateResponse().parse(result.stdout_bytes)

    # Check file names using set comparison
    file_names = {f.name for f in response.files}
    expected_files = {
        "database/__codegen_db__/__init__.py",  # Main database init + queries init (same path, will be one file)
        "database/__codegen_db__/models.py",
        "database/__codegen_db__/enums.py",
        "database/__codegen_db__/queries.py",
        "product/__codegen_db__/__init__.py",  # Product queries init
        "product/__codegen_db__/queries.py",
    }
    assert file_names == expected_files

    # Create lookup dictionary for easier file access
    files_by_name = {f.name: f for f in response.files}

    # Check that database queries file contains both database queries
    database_content = files_by_name["database/__codegen_db__/queries.py"].contents.decode("utf-8")
    assert "query_get_user" in database_content
    assert "query_list_users" in database_content
    assert "query_get_product" not in database_content

    # Check that product queries file contains both product queries
    product_content = files_by_name["product/__codegen_db__/queries.py"].contents.decode("utf-8")
    assert "query_get_product" in product_content
    assert "query_list_products" in product_content
    assert "query_get_user" not in product_content

    # Check that __init__.py files are empty
    assert files_by_name["database/__codegen_db__/__init__.py"].contents == b""
    assert files_by_name["product/__codegen_db__/__init__.py"].contents == b""


def test_partial_model_query_generation():
    """Test that queries selecting subset of columns generate custom dataclasses."""
    # Create a catalog with a table
    catalog = Catalog(
        name="test_db",
        schemas=[
            Schema(
                name="public",
                tables=[
                    Table(
                        rel=Identifier(name="users", schema="public"),
                        columns=[
                            Column(name="id", not_null=True, type=Identifier(name="bigint")),
                            Column(name="name", not_null=True, type=Identifier(name="text")),
                            Column(name="email", not_null=False, type=Identifier(name="text")),
                            Column(name="created_at", not_null=True, type=Identifier(name="timestamptz")),
                            Column(name="metadata", not_null=False, type=Identifier(name="jsonb")),
                        ],
                    )
                ],
            )
        ],
    )

    # Create queries - one full model, one partial
    queries = [
        # Full model query (selects ALL columns)
        Query(
            name="get_user_full",
            text="SELECT id, name, email, created_at, metadata FROM users WHERE id = $1",
            cmd=":one",
            params=[Parameter(number=1, column=Column(name="id", not_null=True, type=Identifier(name="bigint")))],
            columns=[
                Column(name="id", not_null=True, type=Identifier(name="bigint"), table=Identifier(name="users")),
                Column(name="name", not_null=True, type=Identifier(name="text"), table=Identifier(name="users")),
                Column(name="email", not_null=False, type=Identifier(name="text"), table=Identifier(name="users")),
                Column(name="created_at", not_null=True, type=Identifier(name="timestamptz"), table=Identifier(name="users")),
                Column(name="metadata", not_null=False, type=Identifier(name="jsonb"), table=Identifier(name="users")),
            ],
        ),
        # Partial model query (selects only name and email)
        Query(
            name="get_user_summary",
            text="SELECT id, name FROM users WHERE id = $1",
            cmd=":one",
            params=[Parameter(number=1, column=Column(name="id", not_null=True, type=Identifier(name="bigint")))],
            columns=[
                Column(name="id", not_null=True, type=Identifier(name="bigint"), table=Identifier(name="users")),
                Column(name="name", not_null=True, type=Identifier(name="text"), table=Identifier(name="users")),
            ],
        ),
        # Multi-table JOIN query (should also get custom dataclass)
        Query(
            name="get_user_with_posts_count",
            text="SELECT u.name, COUNT(p.id) as post_count FROM users u LEFT JOIN posts p ON u.id = p.user_id WHERE u.id = $1",
            cmd=":one",
            params=[Parameter(number=1, column=Column(name="id", not_null=True, type=Identifier(name="bigint")))],
            columns=[
                Column(name="name", not_null=True, type=Identifier(name="text"), table=Identifier(name="users")),
                Column(name="post_count", not_null=True, type=Identifier(name="bigint")),  # No table - computed column
            ],
        ),
    ]

    # Generate queries
    queries_code = generate_queries(queries, catalog)

    # Check the generated code structure
    expected_code = '''\
# Code generated by sqlc. DO NOT EDIT.
import dataclasses
import datetime
from typing import Any, AsyncIterator
import sqlalchemy
import psycopg
from database.conn import DBConn
from database.__codegen_db__ import models
from foundation.observability.errors import NotFoundError

@dataclasses.dataclass(slots=True)
class GetUserSummaryResult:
    id: int
    name: str

@dataclasses.dataclass(slots=True)
class GetUserWithPostsCountResult:
    name: str
    post_count: int

GET_USER_FULL = """\\
SELECT id, name, email, created_at, metadata FROM users WHERE id = :p1
"""

async def query_get_user_full(conn: DBConn, *, id: int) -> models.UserModel:
    row = (await conn.execute(sqlalchemy.text(GET_USER_FULL), {"p1": id})).first()
    if row is None:
        raise NotFoundError(resource="get_user_full", key_name="id", key_value=str(id))
    return models.UserModel(
        id=row[0],
        name=row[1],
        email=row[2],
        created_at=row[3],
        metadata=row[4],
    )

GET_USER_SUMMARY = """\\
SELECT id, name FROM users WHERE id = :p1
"""

async def query_get_user_summary(conn: DBConn, *, id: int) -> GetUserSummaryResult:
    row = (await conn.execute(sqlalchemy.text(GET_USER_SUMMARY), {"p1": id})).first()
    if row is None:
        raise NotFoundError(resource="get_user_summary", key_name="id", key_value=str(id))
    return GetUserSummaryResult(
        id=row[0],
        name=row[1],
    )

GET_USER_WITH_POSTS_COUNT = """\\
SELECT u.name, COUNT(p.id) as post_count FROM users u LEFT JOIN posts p ON u.id = p.user_id WHERE u.id = :p1
"""

async def query_get_user_with_posts_count(conn: DBConn, *, id: int) -> GetUserWithPostsCountResult:
    row = (await conn.execute(sqlalchemy.text(GET_USER_WITH_POSTS_COUNT), {"p1": id})).first()
    if row is None:
        raise NotFoundError(resource="get_user_with_posts_count", key_name="id", key_value=str(id))
    return GetUserWithPostsCountResult(
        name=row[0],
        post_count=row[1],
    )

'''
    assert queries_code == expected_code


def test_partial_model_many_query():
    """Test that :many queries with partial columns also generate custom dataclasses."""
    # Create a catalog with a table
    catalog = Catalog(
        name="test_db",
        schemas=[
            Schema(
                name="public",
                tables=[
                    Table(
                        rel=Identifier(name="products", schema="public"),
                        columns=[
                            Column(name="id", not_null=True, type=Identifier(name="bigint")),
                            Column(name="name", not_null=True, type=Identifier(name="text")),
                            Column(name="description", not_null=False, type=Identifier(name="text")),
                            Column(name="price", not_null=True, type=Identifier(name="numeric")),
                            Column(name="created_at", not_null=True, type=Identifier(name="timestamptz")),
                        ],
                    )
                ],
            )
        ],
    )

    # Create a partial :many query
    queries = [
        Query(
            name="list_product_summaries",
            text="SELECT id, name, price FROM products",
            cmd=":many",
            columns=[
                Column(name="id", not_null=True, type=Identifier(name="bigint"), table=Identifier(name="products")),
                Column(name="name", not_null=True, type=Identifier(name="text"), table=Identifier(name="products")),
                Column(name="price", not_null=True, type=Identifier(name="numeric"), table=Identifier(name="products")),
            ],
        ),
    ]

    # Generate queries
    queries_code = generate_queries(queries, catalog)

    # Check that it generates a custom dataclass and uses AsyncIterator with custom type
    expected_code = '''\
# Code generated by sqlc. DO NOT EDIT.
import dataclasses
import datetime
from typing import Any, AsyncIterator
import sqlalchemy
import psycopg
from database.conn import DBConn
from database.__codegen_db__ import models
from foundation.observability.errors import NotFoundError

@dataclasses.dataclass(slots=True)
class ListProductSummariesResult:
    id: int
    name: str
    price: float

LIST_PRODUCT_SUMMARIES = """\\
SELECT id, name, price FROM products
"""

async def query_list_product_summaries(conn: DBConn) -> AsyncIterator[ListProductSummariesResult]:
    result = await conn.execute(sqlalchemy.text(LIST_PRODUCT_SUMMARIES), {})
    for row in result:
        yield ListProductSummariesResult(
            id=row[0],
            name=row[1],
            price=row[2],
        )

'''
    assert queries_code == expected_code


def test_batch_operations_generation():
    """Test generation of batch operation functions using executemany with upsert examples."""
    # Test data for batch operations with upserts
    queries = [
        Query(
            name="batch_upsert_users",
            text="INSERT INTO users (name, email) VALUES ($1, $2) ON CONFLICT (email) DO UPDATE SET name = EXCLUDED.name",
            cmd=":batchexec",
            params=[
                Parameter(number=1, column=Column(name="name", not_null=True, type=Identifier(name="text"))),
                Parameter(number=2, column=Column(name="email", not_null=True, type=Identifier(name="text"))),
            ],
        ),
        Query(
            name="batch_upsert_products",
            text="INSERT INTO products (name, price, category_id) VALUES ($1, $2, $3) ON CONFLICT (name) DO UPDATE SET price = EXCLUDED.price, category_id = EXCLUDED.category_id RETURNING id, name, price",
            cmd=":batchone",
            columns=[
                Column(name="id", not_null=True, type=Identifier(name="bigint"), table=Identifier(name="products")),
                Column(name="name", not_null=True, type=Identifier(name="text"), table=Identifier(name="products")),
                Column(name="price", not_null=True, type=Identifier(name="numeric"), table=Identifier(name="products")),
            ],
            params=[
                Parameter(number=1, column=Column(name="name", not_null=True, type=Identifier(name="text"))),
                Parameter(number=2, column=Column(name="price", not_null=True, type=Identifier(name="numeric"))),
                Parameter(number=3, column=Column(name="category_id", not_null=True, type=Identifier(name="bigint"))),
            ],
        ),
        Query(
            name="batch_update_inventory",
            text="UPDATE inventory SET quantity = quantity + $1 WHERE product_id = $2 RETURNING product_id, quantity",
            cmd=":batchmany",
            columns=[
                Column(name="product_id", not_null=True, type=Identifier(name="bigint"), table=Identifier(name="inventory")),
                Column(name="quantity", not_null=True, type=Identifier(name="integer"), table=Identifier(name="inventory")),
            ],
            params=[
                Parameter(number=1, column=Column(name="quantity_delta", not_null=True, type=Identifier(name="integer"))),
                Parameter(number=2, column=Column(name="product_id", not_null=True, type=Identifier(name="bigint"))),
            ],
        ),
    ]

    # Create a catalog to test whether custom dataclasses are needed
    catalog = Catalog(
        name="test_db",
        schemas=[
            Schema(
                name="public",
                tables=[
                    Table(
                        rel=Identifier(name="users", schema="public"),
                        columns=[
                            Column(name="id", not_null=True, type=Identifier(name="bigint")),
                            Column(name="name", not_null=True, type=Identifier(name="text")),
                            Column(name="email", not_null=True, type=Identifier(name="text")),
                        ],
                    ),
                    Table(
                        rel=Identifier(name="products", schema="public"),
                        columns=[
                            Column(name="id", not_null=True, type=Identifier(name="bigint")),
                            Column(name="name", not_null=True, type=Identifier(name="text")),
                            Column(name="price", not_null=True, type=Identifier(name="numeric")),
                            Column(name="category_id", not_null=True, type=Identifier(name="bigint")),
                        ],
                    ),
                    Table(
                        rel=Identifier(name="inventory", schema="public"),
                        columns=[
                            Column(name="product_id", not_null=True, type=Identifier(name="bigint")),
                            Column(name="quantity", not_null=True, type=Identifier(name="integer")),
                        ],
                    ),
                ],
            )
        ],
    )

    # Generate queries code
    queries_code = generate_queries(queries, catalog)

    expected_code = '''\
# Code generated by sqlc. DO NOT EDIT.
import dataclasses
import datetime
from typing import Any, AsyncIterator
import sqlalchemy
import psycopg
from database.conn import DBConn
from database.__codegen_db__ import models
from foundation.observability.errors import NotFoundError

@dataclasses.dataclass(slots=True)
class BatchUpsertUsersData:
    name: str
    email: str

@dataclasses.dataclass(slots=True)
class BatchUpsertProductsData:
    name: str
    price: float
    category_id: int

@dataclasses.dataclass(slots=True)
class BatchUpsertProductsResult:
    id: int
    name: str
    price: float

@dataclasses.dataclass(slots=True)
class BatchUpdateInventoryData:
    quantity_delta: int
    product_id: int

BATCH_UPSERT_USERS = """\\
INSERT INTO users (name, email) VALUES (:p1, :p2) ON CONFLICT (email) DO UPDATE SET name = EXCLUDED.name
"""

async def query_batch_upsert_users(conn: DBConn, batch_data: list[BatchUpsertUsersData]) -> None:
    await conn.execute(sqlalchemy.text(BATCH_UPSERT_USERS), [{"p1": batch_item.name, "p2": batch_item.email} for batch_item in batch_data])

BATCH_UPSERT_PRODUCTS = """\\
INSERT INTO products (name, price, category_id) VALUES (%(p1)s, %(p2)s, %(p3)s) ON CONFLICT (name) DO UPDATE SET price = EXCLUDED.price, category_id = EXCLUDED.category_id RETURNING id, name, price
"""

async def query_batch_upsert_products(conn: DBConn, batch_data: list[BatchUpsertProductsData]) -> AsyncIterator[BatchUpsertProductsResult]:
    raw_conn = await conn.get_raw_connection()
    assert raw_conn.driver_connection
    async with raw_conn.driver_connection.cursor() as cursor:
        await cursor.executemany(BATCH_UPSERT_PRODUCTS, [{"p1": batch_item.name, "p2": batch_item.price, "p3": batch_item.category_id} for batch_item in batch_data], returning=True)
        # For executemany with returning=True, we need to iterate through all result sets
        assert cursor.pgresult
        while True:
            async for row in cursor:
                yield BatchUpsertProductsResult(
                    id=row[0],
                    name=row[1],
                    price=row[2],
                )
            if not cursor.nextset():
                break

BATCH_UPDATE_INVENTORY = """\\
UPDATE inventory SET quantity = quantity + %(p1)s WHERE product_id = %(p2)s RETURNING product_id, quantity
"""

async def query_batch_update_inventory(conn: DBConn, batch_data: list[BatchUpdateInventoryData]) -> AsyncIterator[models.InventoryModel]:
    raw_conn = await conn.get_raw_connection()
    assert raw_conn.driver_connection
    async with raw_conn.driver_connection.cursor() as cursor:
        await cursor.executemany(BATCH_UPDATE_INVENTORY, [{"p1": batch_item.quantity_delta, "p2": batch_item.product_id} for batch_item in batch_data], returning=True)
        # For executemany with returning=True, we need to iterate through all result sets
        assert cursor.pgresult
        while True:
            async for row in cursor:
                yield models.InventoryModel(
                    product_id=row[0],
                    quantity=row[1],
                )
            if not cursor.nextset():
                break

'''
    assert queries_code == expected_code
