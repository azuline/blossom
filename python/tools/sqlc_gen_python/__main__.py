#!/usr/bin/env python3

# Generate proto.py with:
# python -m grpc_tools.protoc -I tools/sqlc_gen_python --python_betterproto_out=tools/sqlc_gen_python

import asyncio
import itertools
import re
import sys
from collections import defaultdict
from pathlib import Path

import click
import jinja2
import sqlalchemy

from database.conn import connect_db_admin
from tools.sqlc_gen_python.proto import Catalog, Column, File, GenerateRequest, GenerateResponse, Parameter, Query

MODELS_TEMPLATE = """\
# Code generated by sqlc. DO NOT EDIT.
import dataclasses
import datetime
from typing import Any

{% if has_enums -%}
from database.__codegen_db__ import enums
{% endif -%}

{% for table in tables -%}
@dataclasses.dataclass(slots=True)
class {{ table.class_name }}:
{%- for column in table.columns %}
    {{ column.name }}: {{ column.python_type }}
{%- endfor %}

{% endfor -%}
"""

QUERIES_TEMPLATE = '''\
# Code generated by sqlc. DO NOT EDIT.
import dataclasses
import datetime
from typing import Any, AsyncIterator
import sqlalchemy
import psycopg
from database.conn import DBConn
from database.__codegen_db__ import models
from foundation.observability.errors import NotFoundError

{% for query in queries -%}
{%- if query.cmd == ":copyfrom" -%}
@dataclasses.dataclass(slots=True)
class {{ query.copyfrom_dataclass_name }}:
{%- for param in query.copyfrom_params %}
    {{ param.name }}: {{ param.python_type }}
{%- endfor %}

{% endif -%}
{%- if query.cmd.startswith(":batch") -%}
@dataclasses.dataclass(slots=True)
class {{ query.batch_dataclass_name }}:
{%- for param in query.batch_params %}
    {{ param.name }}: {{ param.python_type }}
{%- endfor %}

{% endif -%}
{%- if query.needs_custom_dataclass -%}
@dataclasses.dataclass(slots=True)
class {{ query.custom_dataclass_name }}:
{%- for column in query.columns %}
    {{ column.name }}: {{ column.python_type }}
{%- endfor %}

{% endif -%}
{%- endfor -%}
{%- for query in queries -%}
{{ query.constant_name }} = r"""-- name: {{ query.name }} \\{{ query.cmd }}
{{ query.text }}
"""

async def query_{{ query.name }}(conn: DBConn{{ query.params_signature }}) -> {{ query.return_type }}:
{%- if query.cmd == ":exec" %}
    await conn.execute(sqlalchemy.text({{ query.constant_name }}), {{ query.param_dict }})
{%- elif query.cmd == ":one" %}
    row = (await conn.execute(sqlalchemy.text({{ query.constant_name }}), {{ query.param_dict }})).first()
    if row is None:
        raise NotFoundError({{ query.error_params }})
{%- if query.columns %}
    {%- if query.needs_custom_dataclass %}
    return {{ query.custom_dataclass_name }}(
    {%- else %}
    return models.{{ query.model_name }}(
    {%- endif %}
{%- for column in query.columns %}
        {{ column.name }}=row[{{ loop.index0 }}],
{%- endfor %}
    )
{%- else %}
    return row
{%- endif %}
{%- elif query.cmd == ":many" %}
    result = await conn.execute(sqlalchemy.text({{ query.constant_name }}), {{ query.param_dict }})
    for row in result:
{%- if query.columns %}
        {%- if query.needs_custom_dataclass %}
        yield {{ query.custom_dataclass_name }}(
        {%- else %}
        yield models.{{ query.model_name }}(
        {%- endif %}
{%- for column in query.columns %}
            {{ column.name }}=row[{{ loop.index0 }}],
{%- endfor %}
        )
{%- else %}
        yield row
{%- endif %}
{%- elif query.cmd == ":batchexec" %}
    await conn.execute(sqlalchemy.text({{ query.constant_name }}), [{{ query.batch_param_dict }} for batch_item in batch_data])
{%- elif query.cmd == ":batchone" %}
    # Use psycopg connection for batch execution with RETURNING
    raw_conn = await conn.get_raw_connection()
    assert raw_conn.driver_connection
    async with raw_conn.driver_connection.cursor() as cursor:
        psycopg_sql = {{ query.psycopg_sql }}
        await cursor.executemany(psycopg_sql, [{{ query.batch_param_dict }} for batch_item in batch_data], returning=True)
        # For executemany with returning=True, we need to iterate through all result sets
        assert cursor.pgresult
        while True:
            async for row in cursor:
{%- if query.columns %}
                {%- if query.needs_custom_dataclass %}
                yield {{ query.custom_dataclass_name }}(
                {%- else %}
                yield models.{{ query.model_name }}(
                {%- endif %}
{%- for column in query.columns %}
                    {{ column.name }}=row[{{ loop.index0 }}],
{%- endfor %}
                )
{%- else %}
                yield row
{%- endif %}
            if not cursor.nextset():
                break
{%- elif query.cmd == ":batchmany" %}
    # Use psycopg connection for batch execution with RETURNING
    raw_conn = await conn.get_raw_connection()
    assert raw_conn.driver_connection
    async with raw_conn.driver_connection.cursor() as cursor:
        psycopg_sql = {{ query.psycopg_sql }}
        await cursor.executemany(psycopg_sql, [{{ query.batch_param_dict }} for batch_item in batch_data], returning=True)
        # For executemany with returning=True, we need to iterate through all result sets
        assert cursor.pgresult
        while True:
            async for row in cursor:
{%- if query.columns %}
                {%- if query.needs_custom_dataclass %}
                yield {{ query.custom_dataclass_name }}(
                {%- else %}
                yield models.{{ query.model_name }}(
                {%- endif %}
{%- for column in query.columns %}
                    {{ column.name }}=row[{{ loop.index0 }}],
{%- endfor %}
                )
{%- else %}
                yield row
{%- endif %}
            if not cursor.nextset():
                break
{%- elif query.cmd == ":copyfrom" %}
    # Use psycopg connection for bulk insert via COPY FROM
    raw_conn = await conn.get_raw_connection()
    assert raw_conn.driver_connection
    async with raw_conn.driver_connection.cursor() as cursor:
        # Convert INSERT statement to COPY FROM format
        copy_sql = f"COPY {{ query.insert_into_table.name }} ({% for param in query.copyfrom_params %}{{ param.name }}{% if not loop.last %}, {% endif %}{% endfor %}) FROM STDIN"
        async with cursor.copy(copy_sql) as copy:
            for item in data:
                await copy.write_row(({% for param in query.copyfrom_params %}item.{{ param.name }}{% if not loop.last %}, {% endif %}{% endfor %}))
{%- endif %}

{% endfor -%}
'''

ENUMS_TEMPLATE = """\
# Code generated by sqlc. DO NOT EDIT.
from typing import Literal

{% for enum in enums -%}
type {{ enum.type_name }} = Literal[{{ enum.literal_values }}]
{{ enum.values_name }} = {{ enum.values_list }}

{% endfor -%}
"""

POSTGRES_TO_PYTHON_TYPES = {
    "text": "str",
    "varchar": "str",
    "char": "str",
    "bpchar": "str",
    "timestamptz": "datetime.datetime",
    "timestamp": "datetime.datetime",
    "date": "datetime.date",
    "time": "datetime.time",
    "timetz": "datetime.time",
    "interval": "datetime.timedelta",
    "boolean": "bool",
    "bool": "bool",
    "jsonb": "dict[str, Any]",
    "json": "dict[str, Any]",
    "bigint": "int",
    "int8": "int",
    "integer": "int",
    "int4": "int",
    "smallint": "int",
    "int2": "int",
    "serial": "int",
    "bigserial": "int",
    "real": "float",
    "float4": "float",
    "double precision": "float",
    "float8": "float",
    "numeric": "float",
    "decimal": "float",
    "money": "float",
    "uuid": "str",
    "bytea": "bytes",
    "inet": "str",
    "cidr": "str",
    "macaddr": "str",
    "point": "str",
    "line": "str",
    "lseg": "str",
    "box": "str",
    "path": "str",
    "polygon": "str",
    "circle": "str",
}


async def _get_enum_foreign_keys() -> dict[tuple[str, str], str]:
    """Query PostgreSQL catalog to get foreign key relationships to enum tables."""
    async with connect_db_admin() as conn:
        result = await conn.execute(
            sqlalchemy.text("""
                SELECT tc.table_name, kcu.column_name, ccu.table_name AS foreign_table_name
                FROM information_schema.table_constraints AS tc
                    JOIN information_schema.key_column_usage AS kcu
                        ON tc.constraint_name = kcu.constraint_name AND tc.table_schema = kcu.table_schema
                    JOIN information_schema.constraint_column_usage AS ccu
                        ON ccu.constraint_name = tc.constraint_name AND ccu.table_schema = tc.table_schema
                WHERE tc.constraint_type = 'FOREIGN KEY' AND tc.table_schema = 'public'
                    AND ccu.table_name LIKE '%_enum'
                ORDER BY tc.table_name, kcu.column_name
            """)
        )

        return {(tbl, col): "".join(w.capitalize() for w in fk_tbl.split("_")) for tbl, col, fk_tbl in result}


def _map_postgres_type_to_python(column: Column, enum_fk_mapping: dict[tuple[str, str], str] | None = None) -> str:
    """Convert PostgreSQL column type to Python type annotation."""
    type_name = column.type.name.lower()

    if enum_fk_mapping and column.table and (fk_key := (column.table.name, column.name)) in enum_fk_mapping:
        python_type = f"enums.{enum_fk_mapping[fk_key]}"
    elif column.is_array or column.array_dims > 0:
        python_type = f"list[{POSTGRES_TO_PYTHON_TYPES.get(type_name, 'Any')}]"
    else:
        python_type = POSTGRES_TO_PYTHON_TYPES.get(type_name, "Any")

    return f"{python_type} | None" if not column.not_null else python_type


def _depluralize_table_name(table_name: str) -> str:
    """Convert plural table names to singular model names."""
    if table_name.endswith("ies"):
        return table_name[:-3] + "y"
    elif table_name.endswith("ves"):
        return table_name[:-3] + "f"
    elif table_name.endswith(("ses", "ches", "xes")):
        return table_name[:-2]
    elif table_name.endswith("s") and not table_name.endswith("ss"):
        return table_name[:-1]
    return table_name


async def generate_models(catalog: Catalog) -> str:
    """Generate Python dataclass models from database catalog."""
    enum_tables = {
        table.rel.name: "".join(word.capitalize() for word in table.rel.name.split("_"))
        for table in itertools.chain(*[s.tables for s in catalog.schemas if s.name == "public"])
        if table.rel.name.endswith("_enum")
    }
    enum_fk_mapping = await _get_enum_foreign_keys() if enum_tables else None
    tables = [
        {
            "class_name": "".join(word.capitalize() for word in _depluralize_table_name(table.rel.name).split("_")) + "Model",
            "columns": [{"name": column.name, "python_type": _map_postgres_type_to_python(column, enum_fk_mapping)} for column in table.columns],
        }
        for table in itertools.chain(*[s.tables for s in catalog.schemas if s.name == "public"])
        if not table.rel.name.endswith("_enum") and not table.rel.name.startswith("_yoyo")
    ]
    return jinja2.Template(MODELS_TEMPLATE).render(tables=tables, has_enums=bool(enum_tables))


async def generate_enums(catalog: Catalog) -> str:
    """Generate Python enum types from _enum suffixed tables."""
    enums = []
    async with connect_db_admin() as conn:
        for t in itertools.chain(*[s.tables for s in catalog.schemas if s.name == "public"]):
            if t.rel.name.endswith("_enum"):
                result = await conn.execute(sqlalchemy.text(f"SELECT value FROM {t.rel.name} ORDER BY value"))
                if values := [row[0] for row in result]:
                    base_name = t.rel.name[:-5]
                    enums.append({
                        "table_name": t.rel.name,
                        "type_name": "".join(word.capitalize() for word in base_name.split("_")) + "Enum",
                        "values_name": base_name.upper() + "_ENUM_VALUES",
                        "literal_values": ", ".join(f'"{value}"' for value in values),
                        "values_list": str(values),
                    })
    return jinja2.Template(ENUMS_TEMPLATE).render(enums=enums)


def _does_query_return_model(query: Query, catalog: Catalog) -> str | None:
    if query.columns and len({c.table.name for c in query.columns}) == 1:
        table_name = query.columns[0].table.name
        table_def = next(t for s in catalog.schemas for t in s.tables if t.rel.name == table_name)
        if {c.name for c in query.columns} == {c.name for c in table_def.columns}:
            return table_name
    return None


def generate_queries(queries: list[Query], catalog: Catalog | None = None) -> str:
    def get_param_name(param: Parameter) -> str:
        return param.column.name or f"p{param.number}"

    def parse_copyfrom_params(query: Query) -> list[dict[str, str]]:
        """Extract parameters from INSERT statement for copyfrom operations."""
        if query.cmd != ":copyfrom":
            return []
        return [{"name": param.column.name, "python_type": _map_postgres_type_to_python(param.column)} for param in query.params]

    def get_copyfrom_dataclass_name(query: Query) -> str:
        """Generate dataclass name for copyfrom operations."""
        if query.cmd != ":copyfrom":
            return ""
        # Convert query name to PascalCase for dataclass name
        return "".join(word.capitalize() for word in query.name.split("_")) + "Data"

    def get_copyfrom_data_type(query: Query) -> str:
        """Generate type-safe data parameter type for copyfrom operations."""
        if query.cmd != ":copyfrom":
            return ""

        dataclass_name = get_copyfrom_dataclass_name(query)
        return f"list[{dataclass_name}]"

    def parse_batch_params(query: Query) -> list[dict[str, str]]:
        """Extract parameters for batch operations."""
        if not query.cmd.startswith(":batch"):
            return []
        return [{"name": param.column.name, "python_type": _map_postgres_type_to_python(param.column)} for param in query.params]

    def get_batch_dataclass_name(query: Query) -> str:
        """Generate dataclass name for batch operations."""
        if not query.cmd.startswith(":batch"):
            return ""
        # Convert query name to PascalCase for dataclass name
        return "".join(word.capitalize() for word in query.name.split("_")) + "Data"

    def convert_sql_params(sql: str, params: list[Parameter]) -> str:
        """Convert PostgreSQL positional parameters ($1, $2) to SQLAlchemy named parameters (:p1, :p2, etc.)."""
        # First escape all existing colons to prevent SQLAlchemy from treating them as parameters
        result = sql.replace(":", "\\:")
        # Then convert PostgreSQL positional parameters to SQLAlchemy named parameters
        for param in params:
            result = result.replace(f"${param.number}", f":p{param.number}")
        return result

    def convert_to_psycopg_params(sql: str) -> str:
        """Convert SQLAlchemy parameters (:p1, :p2) to psycopg named parameters (%(p1)s, %(p2)s) for raw psycopg usage."""
        return re.sub(r":p(\d+)", r"%(p\1)s", sql)

    def get_model_name(query: Query) -> str:
        if query.insert_into_table and query.insert_into_table.name:
            return "".join(w.capitalize() for w in _depluralize_table_name(query.insert_into_table.name).split("_")) + "Model"
        if catalog and query.columns and (table_name := _does_query_return_model(query, catalog)):
            return "".join(word.capitalize() for word in _depluralize_table_name(table_name).split("_")) + "Model"
        return f"{''.join(word.capitalize() for word in query.name.split('_'))}Result"

    def needs_custom_dataclass(query: Query) -> bool:
        """Check if query needs a custom dataclass for partial results."""
        if not query.columns or query.cmd == ":copyfrom" or not catalog:
            return False
        return not _does_query_return_model(query, catalog)

    query_data = [
        {
            "name": query.name,
            "constant_name": query.name.upper(),
            "text": convert_sql_params(query.text, query.params),
            "psycopg_sql": repr(convert_to_psycopg_params(convert_sql_params(query.text, query.params))),
            "cmd": query.cmd,
            "params_signature": (
                f", data: {get_copyfrom_data_type(query)}"
                if query.cmd == ":copyfrom"
                else f", batch_data: list[{get_batch_dataclass_name(query)}]"
                if query.cmd.startswith(":batch")
                else (f", *, {', '.join(f'{get_param_name(p)}: {_map_postgres_type_to_python(p.column)}' for p in query.params)}" if query.params else "")
            ),
            "return_type": {
                ":exec": "None",
                ":one": (get_model_name(query) if needs_custom_dataclass(query) else f"models.{get_model_name(query)}") if query.columns else "Any",
                ":many": (f"AsyncIterator[{get_model_name(query)}]" if needs_custom_dataclass(query) else f"AsyncIterator[models.{get_model_name(query)}]")
                if query.columns
                else "AsyncIterator[Any]",
                ":copyfrom": "None",
                ":batchexec": "None",
                ":batchone": (f"AsyncIterator[{get_model_name(query)}]" if needs_custom_dataclass(query) else f"AsyncIterator[models.{get_model_name(query)}]")
                if query.columns
                else "AsyncIterator[Any]",
                ":batchmany": (f"AsyncIterator[{get_model_name(query)}]" if needs_custom_dataclass(query) else f"AsyncIterator[models.{get_model_name(query)}]")
                if query.columns
                else "AsyncIterator[Any]",
            }.get(query.cmd, "Any"),
            "param_dict": "{" + ", ".join(f'"p{p.number}": {get_param_name(p)}' for p in query.params) + "}" if query.params else "{}",
            "batch_param_dict": "{" + ", ".join(f'"p{p.number}": batch_item.{get_param_name(p)}' for p in query.params) + "}" if query.params else "{}",
            "batch_params": parse_batch_params(query),
            "batch_dataclass_name": get_batch_dataclass_name(query),
            "model_name": get_model_name(query) if query.columns else None,
            "columns": [{"name": col.name, "python_type": _map_postgres_type_to_python(col)} for col in query.columns] if query.columns else None,
            "needs_custom_dataclass": needs_custom_dataclass(query),
            "custom_dataclass_name": get_model_name(query) if needs_custom_dataclass(query) else None,
            "copyfrom_dataclass_name": get_copyfrom_dataclass_name(query),
            "copyfrom_params": parse_copyfrom_params(query),
            "insert_into_table": query.insert_into_table,
            "error_params": (
                # Use query name as snake_case resource name
                f'resource="{query.name}", key_name="{get_param_name(query.params[0])}", key_value=str({get_param_name(query.params[0])})'
                if query.params
                else f'resource="{query.name}", key_name="query", key_value="{query.name}"'
            ),
        }
        for query in queries
    ]

    return jinja2.Template(QUERIES_TEMPLATE).render(queries=query_data)


async def _main_coro() -> None:
    """Async main function to handle database connections."""
    request = GenerateRequest().parse(sys.stdin.buffer.read())
    response = GenerateResponse()

    # Package init
    response.files.append(File(name="database/__codegen_db__/__init__.py", contents=b""))

    # Models
    models_content = await generate_models(request.catalog)
    response.files.append(File(name="database/__codegen_db__/models.py", contents=models_content.encode("utf-8")))

    # Enums
    enums_content = await generate_enums(request.catalog)
    response.files.append(File(name="database/__codegen_db__/enums.py", contents=enums_content.encode("utf-8")))

    # Queries.
    queries_by_filepath = defaultdict(list)
    for query in request.queries:
        queries_by_filepath[query.filepath].append(query)
    cwd = str(Path.cwd().absolute())
    for filepath, queries in queries_by_filepath.items():
        sql_path = Path(filepath)
        assert sql_path.name == "queries.sql"
        output_dir = sql_path.parent / "__codegen_db__"
        output_path = output_dir / "queries.py"
        init_path = output_dir / "__init__.py"
        response.files.append(File(name=str(init_path).removeprefix(cwd), contents=b""))
        queries_content = generate_queries(queries, request.catalog)
        response.files.append(File(name=str(output_path).removeprefix(cwd), contents=queries_content.encode("utf-8")))

    # Respond
    sys.stdout.buffer.write(bytes(response))


@click.command()
@click.argument("service_method", required=True)
def main(service_method: str | None = None) -> None:
    """SQLc Python code generation plugin main entry point."""
    assert service_method == "/plugin.CodegenService/Generate", f"Unexpected service method: {service_method}"
    asyncio.run(_main_coro())


if __name__ == "__main__":
    main()
